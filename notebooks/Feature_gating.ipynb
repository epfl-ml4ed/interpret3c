{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports and setup\n",
    "import sys\n",
    "import os\n",
    "# Necessary to import code from ../scripts/\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/scripts\")\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from preprocessing import preprocess\n",
    "from gating import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_path = '../data/'\n",
    "\n",
    "feature_types = ['lalle_conati', 'boroujeni_et_al', 'chen_cui', 'marras_et_al']\n",
    "metadata = pd.read_csv(data_path + 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = ['analysenumerique_001',\n",
    " 'analysenumerique_002',\n",
    " 'analysenumerique_003',\n",
    " 'cpp_fr_001',\n",
    " 'dsp_001',\n",
    " 'dsp_002',\n",
    " 'dsp_004',\n",
    " 'dsp_005',\n",
    " 'dsp_006',\n",
    " 'geomatique_003',\n",
    " 'hwts_001',\n",
    " 'hwts_002',\n",
    " 'initprogcpp_001',\n",
    " 'microcontroleurs_003',\n",
    " 'microcontroleurs_004',\n",
    " 'microcontroleurs_005',\n",
    " 'microcontroleurs_006',\n",
    " 'progfun_002',\n",
    " 'progfun_003',\n",
    " 'structures_001',\n",
    " 'structures_002',\n",
    " 'structures_003',\n",
    " 'venture_001',\n",
    " 'villesafricaines_001',\n",
    " 'villesafricaines_002',\n",
    " 'villesafricaines_003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature gating with annealing loss\n",
    "\n",
    "Tuning based on sparsity criteria can be accomplished by establishing a set of sparsity targets. Additionally, you have the option to select between two normalization methods: min-max and unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list = [0.4]\n",
    "norm_methods = ['unit', 'min-max']\n",
    "sparsity_target = [0.45, 0.5, 0.55]\n",
    "\n",
    "for course in courses:\n",
    "    \n",
    "    MODEL_PATH = '../models/saved/'\n",
    "    results_path = '../results/'\n",
    "\n",
    "    MODEL_PATH += course + '/'\n",
    "    results_path += course + '/inter-c3/'\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    path = data_path + course + '/'\n",
    "\n",
    "    for percentile in percentile_list:\n",
    "        for sparsity in sparsity_target:\n",
    "            for norm in norm_methods:\n",
    "                x_train, x_test, x_val, y_train, y_test, y_val, feature_names = preprocess(course, path, \n",
    "                                                                                           percentile, \n",
    "                                                                                           feature_types, \n",
    "                                                                                           metadata, \n",
    "                                                                                           normalization=norm)\n",
    "\n",
    "                # Concat features & labels for later analysis\n",
    "                X = np.concatenate([x_train, x_val, x_test], axis=0)\n",
    "                Y = np.concatenate([y_train, y_val, y_test], axis=0)\n",
    "\n",
    "                # Set up parameters and model to train\n",
    "                meta = {'gumbel_temp': 1, 'gumbel_noise': 1e-8}\n",
    "                params = {\n",
    "                    'epochs': 20,\n",
    "                    'batch_size': 64,\n",
    "                    'optimizer': tf.keras.optimizers.Adam(),\n",
    "                    'sparsity_target': sparsity\n",
    "                }\n",
    "                model = MaskingModel(n_groups=x_train.shape[-1])\n",
    "\n",
    "                filename = MODEL_PATH + 'annealing_fg_'+norm+'_norm_'+str(sparsity)+'_perc_'+str(percentile)\n",
    "                \n",
    "                # Train model\n",
    "                print(\"Training model for course {0}, percentile {1} of data and sparsity target {2}\\n\".format(course, percentile, sparsity))\n",
    "                start_time = time.time()\n",
    "                scores = custom_train(model, params, meta, x_train, y_train, \n",
    "                                      x_val, y_val, verbose=True)\n",
    "                print(\"Time spent on training: {0}\".format(time.time()- start_time))\n",
    "                \n",
    "                # Save model\n",
    "                model.save_weights(filename)\n",
    "\n",
    "                np.save(results_path+'scores_'+norm+'_norm_'+str(sparsity)+'.npy', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording balanced accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysenumerique_001\n",
      "analysenumerique_002\n",
      "analysenumerique_003\n",
      "cpp_fr_001\n",
      "dsp_001\n",
      "dsp_002\n",
      "dsp_004\n",
      "dsp_005\n",
      "dsp_006\n",
      "geomatique_003\n",
      "hwts_001\n",
      "hwts_002\n",
      "initprogcpp_001\n",
      "microcontroleurs_003\n",
      "microcontroleurs_004\n",
      "microcontroleurs_005\n",
      "microcontroleurs_006\n",
      "progfun_002\n",
      "progfun_003\n",
      "structures_001\n",
      "structures_002\n",
      "structures_003\n",
      "venture_001\n",
      "villesafricaines_001\n",
      "villesafricaines_002\n",
      "villesafricaines_003\n"
     ]
    }
   ],
   "source": [
    "percentile = 0.4\n",
    "\n",
    "bal_acc = tf.keras.metrics.AUC()\n",
    "\n",
    "for course in courses:\n",
    "    results_path = '../results/' + course + '/inter-c3/'\n",
    "    MODEL_PATH = '../models/saved/' + course + '/'\n",
    "    path = data_path + course + '/'\n",
    "    print(course)\n",
    "    \n",
    "    norm_sparsity = {}\n",
    "    norm_sparsity['unit'] = []\n",
    "    norm_sparsity['min-max'] = []\n",
    "    for f in glob.glob(MODEL_PATH+'*.index'):\n",
    "        f = f.replace(MODEL_PATH, '').replace('.index', '').replace('annealing_fg_', '')\n",
    "        f = f.split('_')\n",
    "        if f[0] == 'unit' or f[0] == 'min-max':\n",
    "            norm_sparsity[f[0]].append(float(f[2]))\n",
    "    norm_sparsity['unit'].sort()\n",
    "    norm_sparsity['min-max'].sort()\n",
    "    \n",
    "    for norm in norm_sparsity.keys():\n",
    "        x_train, x_test, x_val, y_train, y_test, y_val, feature_names = preprocess(course, path, percentile, \n",
    "                                                                                   feature_types, metadata, \n",
    "                                                                                   normalization=norm)\n",
    "        X = np.concatenate([x_train, x_val, x_test], axis=0)\n",
    "        \n",
    "        for sparsity in np.unique(norm_sparsity[norm]):\n",
    "            \n",
    "            meta = {'gumbel_temp': 1, 'gumbel_noise': 1e-8}\n",
    "            model = MaskingModel(n_groups=x_train.shape[-1])\n",
    "\n",
    "            filename = 'annealing_fg_'+norm+'_norm_'+str(sparsity)+'_perc_'+str(percentile)\n",
    "            model.load_weights(MODEL_PATH + filename).expect_partial()\n",
    "            \n",
    "            v_pred = model(x_test, meta, training=False)\n",
    "            \n",
    "            bal_acc.update_state(y_test, v_pred)\n",
    "            v_acc = bal_acc.result()\n",
    "            bal_acc.reset_state()\n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(results_path+'test_acc_'+norm+'_norm_'+str(sparsity)+'.npy', v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

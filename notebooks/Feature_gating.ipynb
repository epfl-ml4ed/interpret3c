{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports and setup\n",
    "import sys\n",
    "import os\n",
    "# Necessary to import code from ../scripts/\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/scripts\")\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from preprocessing import preprocess\n",
    "from gating import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_path = '../data/'\n",
    "\n",
    "feature_types = ['lalle_conati', 'boroujeni_et_al', 'chen_cui', 'marras_et_al']\n",
    "metadata = pd.read_csv(data_path + 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = ['analysenumerique_001',\n",
    " 'analysenumerique_002',\n",
    " 'analysenumerique_003',\n",
    " 'cpp_fr_001',\n",
    " 'dsp_001',\n",
    " 'dsp_002',\n",
    " 'dsp_004',\n",
    " 'dsp_005',\n",
    " 'dsp_006',\n",
    " 'geomatique_003',\n",
    " 'hwts_001',\n",
    " 'hwts_002',\n",
    " 'initprogcpp_001',\n",
    " 'microcontroleurs_003',\n",
    " 'microcontroleurs_003_003',\n",
    " 'microcontroleurs_004',\n",
    " 'microcontroleurs_005',\n",
    " 'microcontroleurs_006',\n",
    " 'progfun_002',\n",
    " 'progfun_003',\n",
    " 'structures_001',\n",
    " 'structures_002',\n",
    " 'structures_003',\n",
    " 'venture_001',\n",
    " 'villesafricaines_001',\n",
    " 'villesafricaines_002',\n",
    " 'villesafricaines_003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature gating with annealing loss\n",
    "\n",
    "Fine-tuning based on sparsity criteria can be accomplished by establishing a set of sparsity targets. Additionally, you have the option to select between two normalization methods: min-max and unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list = [0.4]\n",
    "norm_methods = ['unit', 'min-max']\n",
    "sparsity_target = [0.45, 0.5, 0.55]\n",
    "\n",
    "for course in courses:\n",
    "    \n",
    "    MODEL_PATH = '../models/saved/'\n",
    "    results_path = '../results/'\n",
    "\n",
    "    MODEL_PATH += course + '/'\n",
    "    results_path += course + '/inter-c3/'\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    path = data_path + course + '/'\n",
    "\n",
    "    for percentile in percentile_list:\n",
    "        for sparsity in sparsity_target:\n",
    "            for norm in norm_methods:\n",
    "                x_train, x_test, x_val, y_train, y_test, y_val, feature_names = preprocess(course, path, \n",
    "                                                                                           percentile, \n",
    "                                                                                           feature_types, \n",
    "                                                                                           metadata, \n",
    "                                                                                           normalization=norm)\n",
    "\n",
    "                # Concat features & labels for later analysis\n",
    "                X = np.concatenate([x_train, x_val, x_test], axis=0)\n",
    "                Y = np.concatenate([y_train, y_val, y_test], axis=0)\n",
    "\n",
    "                # Set up parameters and model to train\n",
    "                meta = {'gumbel_temp': 1, 'gumbel_noise': 1e-8}\n",
    "                params = {\n",
    "                    'epochs': 20,\n",
    "                    'batch_size': 64,\n",
    "                    'optimizer': tf.keras.optimizers.Adam(),\n",
    "                    'sparsity_target': sparsity\n",
    "                }\n",
    "                model = MaskingModel(n_groups=x_train.shape[-1])\n",
    "\n",
    "                filename = MODEL_PATH + 'annealing_fg_'+norm+'_norm_'+str(sparsity)+'_perc_'+str(percentile)\n",
    "                \n",
    "                # Train model\n",
    "                print(\"Training model for course {0}, percentile {1} of data and sparsity target {2}\\n\".format(course, percentile, sparsity))\n",
    "                start_time = time.time()\n",
    "                scores = custom_train(model, params, meta, x_train, y_train, \n",
    "                                      x_val, y_val, verbose=True)\n",
    "                print(\"Time spent on training: {0}\".format(time.time()- start_time))\n",
    "                \n",
    "                # Save model\n",
    "                model.save_weights(filename)\n",
    "\n",
    "                np.save(results_path+'scores_'+norm+'_norm_'+str(sparsity)+'.npy', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
